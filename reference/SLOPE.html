<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Sorted L-One Penalized Estimation — SLOPE • SLOPE</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Sorted L-One Penalized Estimation — SLOPE"><meta property="og:description" content="Fit a generalized linear model regularized with the
sorted L1 norm, which applies a
non-increasing regularization sequence to the
coefficient vector (\(\beta\)) after having sorted it
in decreasing order according  to its absolute values."><meta property="og:image" content="https://jolars.github.io/SLOPE/logo.svg"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-85513662-2"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-85513662-2');
</script></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SLOPE</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.4.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/introduction.html">An introduction to SLOPE</a>
    </li>
    <li>
      <a href="../articles/prox-algs.html">Proximal Operator Algorithms</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    News
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li class="dropdown-header">Releases</li>
    <li>
      <a href="https://larssonjohan.com/post/slope-0-2-0/" class="external-link">Version 0.2.0</a>
    </li>
    <li class="divider">
    <li>
      <a href="../news/index.html">Changelog</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/jolars/SLOPE/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Sorted L-One Penalized Estimation</h1>
    <small class="dont-index">Source: <a href="https://github.com/jolars/SLOPE/blob/HEAD/R/SLOPE.R" class="external-link"><code>R/SLOPE.R</code></a></small>
    <div class="hidden name"><code>SLOPE.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Fit a generalized linear model regularized with the
sorted L1 norm, which applies a
non-increasing regularization sequence to the
coefficient vector (\(\beta\)) after having sorted it
in decreasing order according  to its absolute values.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="fu">SLOPE</span><span class="op">(</span>
  <span class="va">x</span>,
  <span class="va">y</span>,
  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>, <span class="st">"binomial"</span>, <span class="st">"multinomial"</span>, <span class="st">"poisson"</span><span class="op">)</span>,
  intercept <span class="op">=</span> <span class="cn">TRUE</span>,
  center <span class="op">=</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/class.html" class="external-link">inherits</a></span><span class="op">(</span><span class="va">x</span>, <span class="st">"sparseMatrix"</span><span class="op">)</span>,
  scale <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"l2"</span>, <span class="st">"l1"</span>, <span class="st">"sd"</span>, <span class="st">"none"</span><span class="op">)</span>,
  alpha <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"path"</span>, <span class="st">"estimate"</span><span class="op">)</span>,
  lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"bh"</span>, <span class="st">"gaussian"</span>, <span class="st">"oscar"</span>, <span class="st">"lasso"</span><span class="op">)</span>,
  alpha_min_ratio <span class="op">=</span> <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NCOL</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="fl">0.01</span> <span class="kw">else</span> <span class="fl">1e-04</span>,
  path_length <span class="op">=</span> <span class="kw">if</span> <span class="op">(</span><span class="va">alpha</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">==</span> <span class="st">"estimate"</span><span class="op">)</span> <span class="fl">1</span> <span class="kw">else</span> <span class="fl">20</span>,
  q <span class="op">=</span> <span class="fl">0.1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NCOL</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>,
  theta1 <span class="op">=</span> <span class="fl">1</span>,
  theta2 <span class="op">=</span> <span class="fl">0.5</span>,
  prox_method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"stack"</span>, <span class="st">"pava"</span><span class="op">)</span>,
  screen <span class="op">=</span> <span class="cn">TRUE</span>,
  screen_alg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"strong"</span>, <span class="st">"previous"</span><span class="op">)</span>,
  tol_dev_change <span class="op">=</span> <span class="fl">1e-05</span>,
  tol_dev_ratio <span class="op">=</span> <span class="fl">0.995</span>,
  max_variables <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">NROW</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,
  solver <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"fista"</span>, <span class="st">"admm"</span><span class="op">)</span>,
  max_passes <span class="op">=</span> <span class="fl">1e+06</span>,
  tol_abs <span class="op">=</span> <span class="fl">1e-05</span>,
  tol_rel <span class="op">=</span> <span class="fl">1e-04</span>,
  tol_rel_gap <span class="op">=</span> <span class="fl">1e-05</span>,
  tol_infeas <span class="op">=</span> <span class="fl">0.001</span>,
  tol_rel_coef_change <span class="op">=</span> <span class="fl">0.001</span>,
  diagnostics <span class="op">=</span> <span class="cn">FALSE</span>,
  verbosity <span class="op">=</span> <span class="fl">0</span>,
  <span class="va">sigma</span>,
  <span class="va">n_sigma</span>,
  <span class="va">lambda_min_ratio</span>
<span class="op">)</span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>x</dt>
<dd><p>the design matrix, which can be either a dense
matrix of the standard <em>matrix</em> class, or a sparse matrix
inheriting from <a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">Matrix::sparseMatrix</a>. Data frames will
be converted to matrices internally.</p></dd>
<dt>y</dt>
<dd><p>the response, which for <code>family = "gaussian"</code> must be numeric; for
<code>family = "binomial"</code> or <code>family = "multinomial"</code>, it can be a factor.</p></dd>
<dt>family</dt>
<dd><p>model family (objective); see <strong>Families</strong> for details.</p></dd>
<dt>intercept</dt>
<dd><p>whether to fit an intercept</p></dd>
<dt>center</dt>
<dd><p>whether to center predictors or not by their mean. Defaults
to <code>TRUE</code> if <code>x</code> is dense and <code>FALSE</code> otherwise.</p></dd>
<dt>scale</dt>
<dd><p>type of scaling to apply to predictors.</p><ul><li><p><code>"l1"</code> scales predictors to have L1 norms of one.</p></li>
<li><p><code>"l2"</code> scales predictors to have L2 norms of one.#'</p></li>
<li><p><code>"sd"</code> scales predictors to have a population standard deviation one.</p></li>
<li><p><code>"none"</code> applies no scaling.</p></li>
</ul></dd>
<dt>alpha</dt>
<dd><p>scale for regularization path: either a decreasing numeric
vector (possibly of length 1) or a character vector; in the latter case,
the choices are:</p><ul><li><p><code>"path"</code>, which computes a regularization sequence
where the first value corresponds to the intercept-only (null) model and
the last to the almost-saturated model, and</p></li>
<li><p><code>"estimate"</code>, which estimates a <em>single</em> <code>alpha</code>
using Algorithm 5 in Bogdan et al. (2015).</p></li>
</ul><p>When a value is manually entered for <code>alpha</code>, it will be scaled based
on the type of standardization that is applied to <code>x</code>. For <code>scale = "l2"</code>,
<code>alpha</code> will be scaled by \(\sqrt n\). For <code>scale = "sd"</code> or <code>"none"</code>,
alpha will be scaled by \(n\), and for <code>scale = "l1"</code> no scaling is
applied. Note, however, that the <code>alpha</code> that is returned in the
resulting value is the <strong>unstandardized</strong> alpha.</p></dd>
<dt>lambda</dt>
<dd><p>either a character vector indicating the method used
to construct the lambda path or a numeric non-decreasing
vector with length equal to the number
of coefficients in the model; see section <strong>Regularization sequences</strong>
for details.</p></dd>
<dt>alpha_min_ratio</dt>
<dd><p>smallest value for <code>lambda</code> as a fraction of
<code>lambda_max</code>; used in the selection of <code>alpha</code> when <code>alpha = "path"</code>.</p></dd>
<dt>path_length</dt>
<dd><p>length of regularization path; note that the path
returned may still be shorter due to the early termination criteria
given by <code>tol_dev_change</code>, <code>tol_dev_ratio</code>, and <code>max_variables</code>.</p></dd>
<dt>q</dt>
<dd><p>parameter controlling the shape of the lambda sequence, with
usage varying depending on the type of path used and has no effect
is a custom <code>lambda</code> sequence is used. Must be greater than <code>1e-6</code> and
smaller than 1.</p></dd>
<dt>theta1</dt>
<dd><p>parameter controlling the shape of the lambda sequence
when <code>lambda == "OSCAR"</code>. This parameter basically sets the intercept
for the lambda sequence and is equivalent to \(\lambda_1\) in the
original OSCAR formulation.</p></dd>
<dt>theta2</dt>
<dd><p>parameter controlling the shape of the lambda sequence
when <code>lambda == "OSCAR"</code>. This parameter basically sets the slope
for the lambda sequence and is equivalent to \(\lambda_2\) in the
original OSCAR formulation.</p></dd>
<dt>prox_method</dt>
<dd><p>method for calculating the proximal operator for
the Sorted L1 Norm (the SLOPE penalty). Please see <code><a href="sortedL1Prox.html">sortedL1Prox()</a></code> for
more information.</p></dd>
<dt>screen</dt>
<dd><p>whether to use predictor screening rules (rules that allow
some predictors to be discarded prior to fitting), which improve speed
greatly when the number of predictors is larger than the number
of observations.</p></dd>
<dt>screen_alg</dt>
<dd><p>what type of screening algorithm to use.</p><ul><li><p><code>"strong"</code> uses the set from the strong screening rule and check
against the full set</p></li>
<li><p><code>"previous"</code> first fits with the previous active set, then checks
against the strong set, and finally against the full set if there are
no violations in the strong set</p></li>
</ul></dd>
<dt>tol_dev_change</dt>
<dd><p>the regularization path is stopped if the
fractional change in deviance falls below this value; note that this is
automatically set to 0 if a alpha is manually entered</p></dd>
<dt>tol_dev_ratio</dt>
<dd><p>the regularization path is stopped if the
deviance ratio \(1 - \mathrm{deviance}/\mathrm{(null-deviance)}
  \) is above this threshold</p></dd>
<dt>max_variables</dt>
<dd><p>criterion for stopping the path in terms of the
maximum number of unique, nonzero coefficients in absolute value in model.
For the multinomial family, this value will be multiplied internally with
the number of levels of the response minus one.</p></dd>
<dt>solver</dt>
<dd><p>type of solver use, either <code>"fista"</code> or <code>"admm"</code>;
all families currently support FISTA but only <code>family = "gaussian"</code>
supports ADMM.</p></dd>
<dt>max_passes</dt>
<dd><p>maximum number of passes (outer iterations) for solver</p></dd>
<dt>tol_abs</dt>
<dd><p>absolute tolerance criterion for ADMM solver</p></dd>
<dt>tol_rel</dt>
<dd><p>relative tolerance criterion for ADMM solver</p></dd>
<dt>tol_rel_gap</dt>
<dd><p>stopping criterion for the duality gap; used only with
FISTA solver.</p></dd>
<dt>tol_infeas</dt>
<dd><p>stopping criterion for the level of infeasibility; used
with FISTA solver and KKT checks in screening algorithm.</p></dd>
<dt>tol_rel_coef_change</dt>
<dd><p>relative tolerance criterion for change
in coefficients between iterations, which is reached when
the maximum absolute change in any coefficient divided by the maximum
absolute coefficient size is less than this value.</p></dd>
<dt>diagnostics</dt>
<dd><p>whether to save diagnostics from the solver
(timings and other values depending on type of solver)</p></dd>
<dt>verbosity</dt>
<dd><p>level of verbosity for displaying output from the
program. Setting this to 1 displays basic information on the path level,
2 a little bit more information on the path level, and 3 displays
information from the solver.</p></dd>
<dt>sigma</dt>
<dd><p>deprecated; please use <code>alpha</code> instead</p></dd>
<dt>n_sigma</dt>
<dd><p>deprecated; please use <code>path_length</code> instead</p></dd>
<dt>lambda_min_ratio</dt>
<dd><p>deprecated; please use <code>alpha_min_ratio</code> instead</p></dd>
</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>An object of class <code>"SLOPE"</code> with the following slots:</p>
<dl><dt>coefficients</dt>
<dd><p>a three-dimensional array of the coefficients from the
model fit, including the intercept if it was fit.
There is one row for each coefficient, one column
for each target (dependent variable), and
one slice for each penalty.</p></dd>
<dt>nonzeros</dt>
<dd><p>a three-dimensional logical array indicating whether a
coefficient was zero or not</p></dd>
<dt>lambda</dt>
<dd><p>the lambda vector that when multiplied by a value in <code>alpha</code>
gives the penalty vector at that point along the regularization
path</p></dd>
<dt>alpha</dt>
<dd><p>vector giving the (unstandardized) scaling of the lambda sequence</p></dd>
<dt>class_names</dt>
<dd><p>a character vector giving the names of the classes for binomial and
multinomial families</p></dd>
<dt>passes</dt>
<dd><p>the number of passes the solver took at each step on the path</p></dd>
<dt>violations</dt>
<dd><p>the number of violations of the screening rule at each step on the path;
only available if <code>diagnostics = TRUE</code> in the call to <code>SLOPE()</code>.</p></dd>
<dt>active_sets</dt>
<dd><p>a list where each element indicates the indices of the
coefficients that were active at that point in the regularization path</p></dd>
<dt>unique</dt>
<dd><p>the number of unique predictors (in absolute value)</p></dd>
<dt>deviance_ratio</dt>
<dd><p>the deviance ratio (as a fraction of 1)</p></dd>
<dt>null_deviance</dt>
<dd><p>the deviance of the null (intercept-only) model</p></dd>
<dt>family</dt>
<dd><p>the name of the family used in the model fit</p></dd>
<dt>diagnostics</dt>
<dd><p>a <code>data.frame</code> of objective values for the primal and dual problems, as
well as a measure of the infeasibility, time, and iteration; only
available if <code>diagnostics = TRUE</code> in the call to <code>SLOPE()</code>.</p></dd>
<dt>call</dt>
<dd><p>the call used for fitting the model</p></dd>
</dl></div>
    <div id="details">
    <h2>Details</h2>
    <p><code>SLOPE()</code> solves the convex minimization problem
$$
  f(\beta) + \alpha \sum_{i=j}^p \lambda_j |\beta|_{(j)},
$$
where \(f(\beta)\) is a smooth and convex function and
the second part is the sorted L1-norm.
In ordinary least-squares regression,
\(f(\beta)\) is simply the squared norm of the least-squares residuals.
See section <strong>Families</strong> for specifics regarding the various types of
\(f(\beta)\) (model families) that are allowed in <code>SLOPE()</code>.</p>
<p>By default, <code>SLOPE()</code> fits a path of models, each corresponding to
a separate regularization sequence, starting from
the null (intercept-only) model to an almost completely unregularized
model. These regularization sequences are parameterized using
\(\lambda\) and \(\alpha\), with only \(\alpha\) varying along the
path. The length of the path can be manually, but will terminate
prematurely depending on
arguments <code>tol_dev_change</code>, <code>tol_dev_ratio</code>, and <code>max_variables</code>.
This means that unless these arguments are modified, the path is not
guaranteed to be of length <code>path_length</code>.</p>
    </div>
    <div id="families">
    <h2>Families</h2>
    


<p><strong>Gaussian</strong></p>
<p>The Gaussian model (Ordinary Least Squares) minimizes the following
objective:
$$
  \frac{1}{2} \Vert y - X\beta\Vert_2^2
$$</p>
<p><strong>Binomial</strong></p>
<p>The binomial model (logistic regression) has the following objective:
$$
  \sum_{i=1}^n \log\left(1+ \exp\left(
    - y_i \left(x_i^T\beta + \beta_0 \right) \right) \right)
$$
with \(y \in \{-1, 1\}\).</p>
<p><strong>Poisson</strong></p>
<p>In poisson regression, we use the following objective:</p>
<p>$$
  -\sum_{i=1}^n \left(y_i\left(
    x_i^T\beta + \beta_0\right) - \exp\left(x_i^T\beta + \beta_0
  \right)\right)
$$</p>
<p><strong>Multinomial</strong></p>
<p>In multinomial regression, we minimize the full-rank objective
$$
  -\sum_{i=1}^n\left(
    \sum_{k=1}^{m-1} y_{ik}(x_i^T\beta_k + \beta_{0,k})
    - \log\sum_{k=1}^{m-1} \exp\big(x_i^T\beta_k + \beta_{0,k}\big)
  \right)
$$
with \(y_{ik}\) being the element in a \(n\) by \((m-1)\) matrix, where
\(m\) is the number of classes in the response.</p>
    </div>
    <div id="regularization-sequences">
    <h2>Regularization Sequences</h2>
    

<p>There are multiple ways of specifying the <code>lambda</code> sequence
in <code>SLOPE()</code>. It is, first of all, possible to select the sequence manually
by
using a non-increasing
numeric vector, possibly of length one, as argument instead of a character.
The greater the differences are between
consecutive values along the sequence, the more clustering behavior
will the model exhibit. Note, also, that the scale of the \(\lambda\)
vector makes no difference if <code>alpha = NULL</code>, since <code>alpha</code> will be
selected automatically to ensure that the model is completely sparse at the
beginning and almost unregularized at the end. If, however, both
<code>alpha</code> and <code>lambda</code> are manually specified, then the scales of both do
matter, so make sure to choose them wisely.</p>
<p>Instead of choosing the sequence manually, one of the following
automatically generated sequences may be chosen.</p>
<p><strong>BH (Benjamini--Hochberg)</strong></p>
<p>If <code>lambda = "bh"</code>, the sequence used is that referred to
as \(\lambda^{(\mathrm{BH})}\) by Bogdan et al, which sets
\(\lambda\) according to
$$
  \lambda_i = \Phi^{-1}(1 - iq/(2p)),
$$
for \(i=1,\dots,p\), where \(\Phi^{-1}\) is the quantile
function for the standard normal distribution and \(q\) is a parameter
that can be set by the user in the call to <code>SLOPE()</code>.</p>
<p><strong>Gaussian</strong></p>
<p>This penalty sequence is related to BH, such that
$$
  \lambda_i = \lambda^{(\mathrm{BH})}_i
  \sqrt{1 + w(i-1)\cdot \mathrm{cumsum}(\lambda^2)_i},
$$
for \(i=1,\dots,p\), where \(w(k) = 1/(n-k-1)\). We let
\(\lambda_1 = \lambda^{(\mathrm{BH})}_1\) and
adjust the sequence to make sure that it's non-increasing.
Note that if \(p\) is large relative
to \(n\), this option will result in a constant sequence, which is
usually not what you would want.</p>
<p><strong>OSCAR</strong></p>
<p>This sequence comes from Bondell and Reich and is a linear non-increasing
sequence, such that
$$
  \lambda_i = \theta_1 + (p - i)\theta_2.
$$
for \(i = 1,\dots,p\). We use the parametrization from Zhong and Kwok
(2021) but use \(\theta_1\) and \(\theta_2\) instead of \(\lambda_1\)
and \(\lambda_2\) to avoid confusion and abuse of notation.</p>
<p><strong>lasso</strong></p>
<p>SLOPE is exactly equivalent to the
lasso when the sequence of regularization weights is constant, i.e.
$$
  \lambda_i = 1
$$
for \(i = 1,\dots,p\). Here, again, we stress that the fact that
all \(\lambda\) are equal to one does not matter as long as
<code>alpha == NULL</code> since we scale the vector automatically.
Note that this option is only here for academic interest and
to highlight the fact that SLOPE is
a generalization of the lasso. There are more efficient packages, such as
<strong>glmnet</strong> and <strong>biglasso</strong>, for fitting the lasso.</p>
    </div>
    <div id="solvers">
    <h2>Solvers</h2>
    


<p>There are currently two solvers available for SLOPE: FISTA (Beck and
Teboulle 2009) and ADMM (Boyd et al. 2008). FISTA is available for
families but ADMM is currently only available for <code>family = "gaussian"</code>.</p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Bogdan, M., van den Berg, E., Sabatti, C., Su, W., &amp; Candès, E. J. (2015).
SLOPE -- adaptive variable selection via convex optimization. The Annals of
Applied Statistics, 9(3), 1103–1140. doi: <a href="https://doi.org/10/gfgwzt" class="external-link">10/gfgwzt</a></p>
<p>Bondell, H. D., &amp; Reich, B. J. (2008). Simultaneous Regression Shrinkage,
Variable Selection, and Supervised Clustering of Predictors with OSCAR.
Biometrics, 64(1), 115–123. JSTOR.
doi: <a href="https://doi.org/10.1111/j.1541-0420.2007.00843.x" class="external-link">10.1111/j.1541-0420.2007.00843.x</a></p>
<p>Boyd, S., Parikh, N., Chu, E., Peleato, B., &amp; Eckstein, J. (2010).
Distributed Optimization and Statistical Learning via the Alternating
Direction Method of Multipliers. Foundations and Trends® in Machine Learning,
3(1), 1–122. doi: <a href="https://doi.org/10.1561/2200000016" class="external-link">10.1561/2200000016</a></p>
<p>Beck, A., &amp; Teboulle, M. (2009). A Fast Iterative Shrinkage-Thresholding
Algorithm for Linear Inverse Problems. SIAM Journal on Imaging Sciences,
2(1), 183–202. doi: <a href="https://doi.org/10.1137/080716542" class="external-link">10.1137/080716542</a></p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="plot.SLOPE.html">plot.SLOPE()</a></code>, <code><a href="plotDiagnostics.html">plotDiagnostics()</a></code>, <code><a href="score.html">score()</a></code>, <code><a href="predict.SLOPE.html">predict.SLOPE()</a></code>,
<code><a href="trainSLOPE.html">trainSLOPE()</a></code>, <code><a href="coef.SLOPE.html">coef.SLOPE()</a></code>, <code><a href="print.SLOPE.html">print.SLOPE()</a></code>, <code><a href="print.SLOPE.html">print.SLOPE()</a></code>,
<code><a href="deviance.SLOPE.html">deviance.SLOPE()</a></code>, <code><a href="sortedL1Prox.html">sortedL1Prox()</a></code></p></div>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"></span>
<span class="r-in"><span class="co"># Gaussian response, default lambda sequence</span></span>
<span class="r-in"><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">SLOPE</span><span class="op">(</span><span class="va">bodyfat</span><span class="op">$</span><span class="va">x</span>, <span class="va">bodyfat</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="co"># Poisson response, OSCAR-type lambda sequence</span></span>
<span class="r-in"><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">SLOPE</span><span class="op">(</span></span>
<span class="r-in">  <span class="va">abalone</span><span class="op">$</span><span class="va">x</span>,</span>
<span class="r-in">  <span class="va">abalone</span><span class="op">$</span><span class="va">y</span>,</span>
<span class="r-in">  family <span class="op">=</span> <span class="st">"poisson"</span>,</span>
<span class="r-in">  lambda <span class="op">=</span> <span class="st">"oscar"</span>,</span>
<span class="r-in">  theta1 <span class="op">=</span> <span class="fl">1</span>,</span>
<span class="r-in">  theta2 <span class="op">=</span> <span class="fl">0.9</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="co"># Multinomial response, custom alpha and lambda</span></span>
<span class="r-in"><span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">wine</span><span class="op">$</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span class="r-in"><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">wine</span><span class="op">$</span><span class="va">x</span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">0.005</span></span>
<span class="r-in"><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1.8</span><span class="op">)</span>, length.out <span class="op">=</span> <span class="va">p</span> <span class="op">*</span> <span class="va">m</span><span class="op">)</span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">SLOPE</span><span class="op">(</span></span>
<span class="r-in">  <span class="va">wine</span><span class="op">$</span><span class="va">x</span>,</span>
<span class="r-in">  <span class="va">wine</span><span class="op">$</span><span class="va">y</span>,</span>
<span class="r-in">  family <span class="op">=</span> <span class="st">"multinomial"</span>,</span>
<span class="r-in">  lambda <span class="op">=</span> <span class="va">lambda</span>,</span>
<span class="r-in">  alpha <span class="op">=</span> <span class="va">alpha</span></span>
<span class="r-in"><span class="op">)</span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Johan Larsson, Jonas Wallin, Malgorzata Bogdan, Ewout van den Berg, Chiara Sabatti, Emmanuel Candes, Evan Patterson, Weijie Su.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.1.</p>
</div>

      </footer></div>

  


  

  </body></html>

